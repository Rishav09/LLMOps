{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5098964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdbfb0",
   "metadata": {},
   "source": [
    "## Data Loadiing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca346fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b677686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course': 'data-engineering-zoomcamp',\n",
      " 'question': 'Course - What are the prerequisites for this course?',\n",
      " 'section': 'General course-related questions',\n",
      " 'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites'}\n"
     ]
    }
   ],
   "source": [
    "pprint(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bc9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es_client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    # forces 8-compatible headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655ca8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    \n",
    "}\n",
    "}\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac253283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80172ed5441148e8bcb8bb56a58cc089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f871ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do copy a file to a Docker container?'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760a19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "        },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    search_response = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in search_response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92129e",
   "metadata": {},
   "source": [
    "### Retriving seaarch results(brute forced only top-3 results based on score here. Now to add the results as a context, question and prompt to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c990f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    template = (\n",
    "        \"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT \"\n",
    "        \"from the FAQ database. Use only the facts from the CONTEXT when answering.\\n\\n\"\n",
    "        \"QUESTION: {question}\\n\\nCONTEXT:\\n{context}\"\n",
    "    )\n",
    "\n",
    "    # Efficiently assemble the context blocks\n",
    "    blocks = [\n",
    "        f\"section: {doc['section']}\\n\"\n",
    "        f\"question: {doc['question']}\\n\"\n",
    "        f\"answer: {doc['text']}\"\n",
    "        for doc in search_results\n",
    "    ]\n",
    "    context = \"\\n\\n\".join(blocks)\n",
    "\n",
    "    return template.format(question=query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c25951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f17f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT \"\n",
      " 'from the FAQ database. Use only the facts from the CONTEXT when answering.\\n'\n",
      " '\\n'\n",
      " 'QUESTION: How do copy a file to a Docker container?\\n'\n",
      " '\\n'\n",
      " 'CONTEXT:\\n'\n",
      " 'section: 5. Deploying Machine Learning Models\\n'\n",
      " 'question: How do I debug a docker container?\\n'\n",
      " 'answer: Launch the container image in interactive mode and overriding the '\n",
      " 'entrypoint, so that it starts a bash command.\\n'\n",
      " 'docker run -it --entrypoint bash <image>\\n'\n",
      " 'If the container is already running, execute a command in the specific '\n",
      " 'container:\\n'\n",
      " 'docker ps (find the container-id)\\n'\n",
      " 'docker exec -it <container-id> bash\\n'\n",
      " '(Marcos MJD)\\n'\n",
      " '\\n'\n",
      " 'section: 5. Deploying Machine Learning Models\\n'\n",
      " 'question: How do I copy files from my local machine to docker container?\\n'\n",
      " 'answer: You can copy files from your local machine into a Docker container '\n",
      " \"using the docker cp command. Here's how to do it:\\n\"\n",
      " 'To copy a file or directory from your local machine into a running Docker '\n",
      " 'container, you can use the `docker cp command`. The basic syntax is as '\n",
      " 'follows:\\n'\n",
      " 'docker cp /path/to/local/file_or_directory container_id:/path/in/container\\n'\n",
      " 'Hrithik Kumar Advani\\n'\n",
      " '\\n'\n",
      " 'section: 5. Deploying Machine Learning Models\\n'\n",
      " 'question: How do I copy files from a different folder into docker '\n",
      " 'containerâ€™s working directory?\\n'\n",
      " 'answer: You can copy files from your local machine into a Docker container '\n",
      " \"using the docker cp command. Here's how to do it:\\n\"\n",
      " 'In the Dockerfile, you can provide the folder containing the files that you '\n",
      " 'want to copy over. The basic syntax is as follows:\\n'\n",
      " 'COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
      " 'Gopakumar Gopinathan')\n",
      "1607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To copy a file from your local machine to a Docker container, you can use the `docker cp` command. The basic syntax for this operation is as follows:\\n\\n```\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\n```'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    pprint(prompt)\n",
    "    print(len(prompt))\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "prompt= rag(query)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfdc6cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To copy a file from your local machine to a Docker container, you can use the `docker cp` command. The basic syntax for this operation is as follows:\\n\\n```\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\n```'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71aac5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculating the tokens - \n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "len(encoding.encode(prompt))  # 2048 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60357e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"You're\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode_single_token_bytes(63842)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca0ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
